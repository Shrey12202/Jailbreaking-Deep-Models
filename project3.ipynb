{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40004cc9",
   "metadata": {},
   "source": [
    "Task 1: Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ed5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76655663",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae374e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map your class index to the real ImageNet label index\n",
    "with open(\"./TestDataSet/labels_list.json\") as f:\n",
    "    label_list = json.load(f)\n",
    "\n",
    "class_to_imagenet_idx = {i: int(entry.split(\":\")[0]) for i, entry in enumerate(label_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63ce0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\"./TestDataSet\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = torchvision.models.resnet34(weights='IMAGENET1K_V1').to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a438924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:35<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.7600, Top-5 Accuracy: 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_topk(model, dataloader, topk=(1, 5)):\n",
    "    model.eval()\n",
    "    top1_correct, top5_correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, pred_top5 = outputs.topk(5, 1, True, True)\n",
    "\n",
    "            # Map ground truth labels to real ImageNet indices\n",
    "            mapped_labels = torch.tensor(\n",
    "                [class_to_imagenet_idx[l.item()] for l in labels], device=device\n",
    "            )\n",
    "\n",
    "            pred_top1 = pred_top5[:, 0]\n",
    "            top1_correct += (pred_top1 == mapped_labels).sum().item()\n",
    "            top5_correct += sum([mapped_labels[i] in pred_top5[i] for i in range(len(mapped_labels))])\n",
    "            total += labels.size(0)\n",
    "    return top1_correct / total, top5_correct / total\n",
    "\n",
    "\n",
    "top1_clean, top5_clean = evaluate_topk(model, test_loader)\n",
    "print(f\"Top-1 Accuracy: {top1_clean:.4f}, Top-5 Accuracy: {top5_clean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a740d5b",
   "metadata": {},
   "source": [
    "Task 2: Pixel-wise attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2275a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    adv_images = images + epsilon * images.grad.sign()\n",
    "    return torch.clamp(adv_images, 0, 1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1243f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:34<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "adv_images_fgsm = []\n",
    "true_labels = []\n",
    "for imgs, lbls in tqdm(test_loader):\n",
    "    adv = fgsm_attack(model, imgs, lbls, epsilon=0.02)\n",
    "    adv_images_fgsm.append(adv)\n",
    "    true_labels.append(lbls)\n",
    "\n",
    "adv_dataset1 = torch.cat(adv_images_fgsm)\n",
    "true_labels1 = torch.cat(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa66c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:32<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Top-1: 0.4320, Top-5: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fgsm_loader = DataLoader(torch.utils.data.TensorDataset(adv_dataset1, true_labels1), batch_size=32)\n",
    "top1_fgsm, top5_fgsm = evaluate_topk(model, fgsm_loader)\n",
    "print(f\"FGSM Top-1: {top1_fgsm:.4f}, Top-5: {top5_fgsm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f17c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L∞ max pixel diff: 2.11790\n"
     ]
    }
   ],
   "source": [
    "max_diff = torch.max(torch.abs(adv_dataset1 - torch.cat([imgs.to(device) for imgs, _ in test_loader])))\n",
    "print(f\"L∞ max pixel diff: {max_diff:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7529a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=img.device)\n",
    "    return img * std[:, None, None] + mean[:, None, None]\n",
    "\n",
    "model.eval()\n",
    "count = 0\n",
    "for i in range(len(adv_dataset1)):\n",
    "    orig = test_dataset[i][0].to(device)\n",
    "    adv = adv_dataset1[i].to(device)\n",
    "    label = true_labels1[i].to(device)\n",
    "\n",
    "    pred_orig = model(orig.unsqueeze(0)).argmax(dim=1)\n",
    "    pred_adv = model(adv.unsqueeze(0)).argmax(dim=1)\n",
    "\n",
    "    if pred_orig == label and pred_adv != label:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "        axs[0].imshow(denormalize(orig).permute(1, 2, 0).cpu().numpy())\n",
    "        axs[0].set_title(f\"Original: {pred_orig.item()}\")\n",
    "        axs[1].imshow(denormalize(adv).permute(1, 2, 0).cpu().numpy())\n",
    "        axs[1].set_title(f\"Adversarial: {pred_adv.item()}\")\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f089b7",
   "metadata": {},
   "source": [
    "Task 3: Improved attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, epsilon, alpha, iters):\n",
    "    ori_images = images.clone().detach().to(device)\n",
    "    images = ori_images.clone().detach()\n",
    "    labels = labels.to(device)\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_images = images + alpha * images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - ori_images, min=-epsilon, max=epsilon)\n",
    "        images = torch.clamp(ori_images + eta, 0, 1).detach()\n",
    "    return images\n",
    "\n",
    "adv_images_pgd = []\n",
    "for imgs, lbls in tqdm(test_loader):\n",
    "    adv = pgd_attack(model, imgs, lbls, epsilon=0.02, alpha=0.005, iters=5)\n",
    "    adv_images_pgd.append(adv)\n",
    "\n",
    "adv_dataset2 = torch.cat(adv_images_pgd)\n",
    "pgd_loader = DataLoader(torch.utils.data.TensorDataset(adv_dataset2, true_labels1), batch_size=32)\n",
    "top1_pgd, top5_pgd = evaluate_topk(model, pgd_loader)\n",
    "print(f\"PGD Top-1: {top1_pgd:.4f}, Top-5: {top5_pgd:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865495c",
   "metadata": {},
   "source": [
    "Task 4: Patch attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5dbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attack(model, images, labels, epsilon, patch_size=32):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "    B, C, H, W = images.size()\n",
    "    x = np.random.randint(0, H - patch_size)\n",
    "    y = np.random.randint(0, W - patch_size)\n",
    "    patch = images[:, :, x:x+patch_size, y:y+patch_size].clone().detach()\n",
    "    patch.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    adv_patch = patch + epsilon * patch.grad.sign()\n",
    "    images[:, :, x:x+patch_size, y:y+patch_size] = torch.clamp(adv_patch, 0, 1)\n",
    "    return images.detach()\n",
    "\n",
    "adv_images_patch = []\n",
    "for imgs, lbls in tqdm(test_loader):\n",
    "    adv = patch_attack(model, imgs, lbls, epsilon=0.3, patch_size=32)\n",
    "    adv_images_patch.append(adv)\n",
    "\n",
    "adv_dataset3 = torch.cat(adv_images_patch)\n",
    "patch_loader = DataLoader(torch.utils.data.TensorDataset(adv_dataset3, true_labels1), batch_size=32)\n",
    "top1_patch, top5_patch = evaluate_topk(model, patch_loader)\n",
    "print(f\"Patch Attack Top-1: {top1_patch:.4f}, Top-5: {top5_patch:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819d5e7",
   "metadata": {},
   "source": [
    "Task 5: Transferring attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = torchvision.models.densenet121(weights='IMAGENET1K_V1').to(device).eval()\n",
    "\n",
    "top1_clean_dn, top5_clean_dn = evaluate_topk(densenet, test_loader)\n",
    "top1_fgsm_dn, top5_fgsm_dn = evaluate_topk(densenet, fgsm_loader)\n",
    "top1_pgd_dn, top5_pgd_dn = evaluate_topk(densenet, pgd_loader)\n",
    "top1_patch_dn, top5_patch_dn = evaluate_topk(densenet, patch_loader)\n",
    "\n",
    "print(\"DenseNet-121 Transferability:\")\n",
    "print(f\"Clean      → Top-1: {top1_clean_dn:.4f}, Top-5: {top5_clean_dn:.4f}\")\n",
    "print(f\"FGSM       → Top-1: {top1_fgsm_dn:.4f}, Top-5: {top5_fgsm_dn:.4f}\")\n",
    "print(f\"PGD        → Top-1: {top1_pgd_dn:.4f}, Top-5: {top5_pgd_dn:.4f}\")\n",
    "print(f\"Patch      → Top-1: {top1_patch_dn:.4f}, Top-5: {top5_patch_dn:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
